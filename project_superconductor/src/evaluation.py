"""
è¶…å¯¼ææ–™ä¸´ç•Œæ¸©åº¦é¢„æµ‹æ¨¡å‹æ€§èƒ½è¯„ä¼°æ¨¡å—
æä¾›æ¨¡å‹å®šé‡è¯„ä¼°æŒ‡æ ‡è®¡ç®—ã€æŠ¥å‘Šç”Ÿæˆå’Œé”™è¯¯æ ·æœ¬åˆ†æåŠŸèƒ½
"""

import torch
import numpy as np
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
import os
import pandas as pd
import sys

# ==================== ç³»ç»Ÿè·¯å¾„é…ç½® ====================
# ç¡®ä¿é¡¹ç›®æ¨¡å—æ­£ç¡®å¯¼å…¥ï¼Œæ”¯æŒå¤šç§è¿è¡Œç¯å¢ƒ
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(current_dir)
sys.path.append(parent_dir)

# åŠ¨æ€å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—ï¼ˆå…¼å®¹ä¸åŒç›®å½•ç»“æ„ï¼‰
try:
    from data_processor import SuperconDataProcessor
    from model import TcPredictorAdvanced
except ImportError:
    from src.data_processor import SuperconDataProcessor
    from src.model import TcPredictorAdvanced


def evaluate_model(model, X_test, y_test, model_name="TcPredictorAdvanced"):
    """
    æ¨¡å‹æ€§èƒ½ç»¼åˆè¯„ä¼°å‡½æ•°
    
    è®¡ç®—å›å½’ä»»åŠ¡å…³é”®è¯„ä¼°æŒ‡æ ‡ï¼ŒåŒ…æ‹¬RÂ²åˆ†æ•°ã€å‡æ–¹è¯¯å·®ã€å‡æ–¹æ ¹è¯¯å·®å’Œå¹³å‡ç»å¯¹è¯¯å·®
    
    å‚æ•°:
        model (nn.Module): å·²è®­ç»ƒçš„PyTorchæ¨¡å‹
        X_test (np.ndarray/torch.Tensor): æµ‹è¯•é›†ç‰¹å¾çŸ©é˜µ
        y_test (np.ndarray/torch.Tensor): æµ‹è¯•é›†çœŸå®æ ‡ç­¾
        model_name (str): æ¨¡å‹åç§°æ ‡è¯†ï¼Œç”¨äºæŠ¥å‘Š
        
    è¿”å›:
        dict: åŒ…å«å„é¡¹è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
    """
    # æ¨¡å‹åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼ï¼ˆç¦ç”¨Dropoutç­‰è®­ç»ƒç‰¹å®šå±‚ï¼‰
    model.eval()
    
    # å¼ºåˆ¶ä½¿ç”¨CPUè®¾å¤‡ç¡®ä¿å…¼å®¹æ€§
    device = torch.device("cpu")
    model.to(device)
    
    # æ•°æ®ç±»å‹ç»Ÿä¸€ï¼šç¡®ä¿è¾“å…¥ä¸ºPyTorchå¼ é‡
    if isinstance(X_test, np.ndarray): 
        X_test = torch.FloatTensor(X_test)
    if isinstance(y_test, np.ndarray): 
        y_test = torch.FloatTensor(y_test)
    
    # æ•°æ®è½¬ç§»åˆ°æŒ‡å®šè®¾å¤‡
    X_test = X_test.to(device)
    y_test = y_test.to(device)
    
    # æ¨ç†é˜¶æ®µï¼šç¦ç”¨æ¢¯åº¦è®¡ç®—ä»¥æå‡æ€§èƒ½
    with torch.no_grad():
        y_pred = model(X_test).cpu().numpy().flatten()
    
    # è½¬æ¢ä¸ºnumpyæ•°ç»„ä¾¿äºè®¡ç®—æŒ‡æ ‡
    y_test = y_test.cpu().numpy().flatten()
    
    # è®¡ç®—å„é¡¹å›å½’è¯„ä¼°æŒ‡æ ‡
    return {
        "model_name": model_name,                            # æ¨¡å‹æ ‡è¯†
        "n_samples": len(y_test),                           # æµ‹è¯•æ ·æœ¬æ•°é‡
        "r2_score": r2_score(y_test, y_pred),               # RÂ²å†³å®šç³»æ•°ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šå¥½ï¼‰
        "mse": mean_squared_error(y_test, y_pred),          # å‡æ–¹è¯¯å·®
        "rmse": np.sqrt(mean_squared_error(y_test, y_pred)), # å‡æ–¹æ ¹è¯¯å·®ï¼ˆå•ä½ä¸ç›®æ ‡ç›¸åŒï¼‰
        "mae": mean_absolute_error(y_test, y_pred)          # å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆé²æ£’æ€§æ›´å¥½ï¼‰
    }


def save_evaluation_report(metrics, filepath="evaluation_report.txt"):
    """
    ç”Ÿæˆå¹¶ä¿å­˜æ ¼å¼åŒ–è¯„ä¼°æŠ¥å‘Š
    
    å‚æ•°:
        metrics (dict): evaluate_modelå‡½æ•°è¿”å›çš„æŒ‡æ ‡å­—å…¸
        filepath (str): æŠ¥å‘Šæ–‡ä»¶ä¿å­˜è·¯å¾„ï¼Œé»˜è®¤"evaluation_report.txt"
    """
    with open(filepath, 'w', encoding='utf-8') as f:
        # æŠ¥å‘Šå¤´éƒ¨ä¿¡æ¯
        f.write("="*60 + "\n")
        f.write("       è¶…å¯¼ææ–™ä¸´ç•Œæ¸©åº¦(Tc)é¢„æµ‹æ¨¡å‹è¯„ä¼°æŠ¥å‘Š\n")
        f.write("="*60 + "\n\n")
        
        # åŸºç¡€ä¿¡æ¯éƒ¨åˆ†
        f.write(f"ğŸ“Š æ¨¡å‹åŸºæœ¬ä¿¡æ¯\n")
        f.write(f"   - æ¨¡å‹åç§°:      {metrics['model_name']}\n")
        f.write(f"   - æµ‹è¯•æ ·æœ¬æ•°:    {metrics['n_samples']:,} æ¡\n\n")
        
        # æ€§èƒ½æŒ‡æ ‡éƒ¨åˆ†
        f.write(f"ğŸ“ˆ æ¨¡å‹æ€§èƒ½æŒ‡æ ‡\n")
        f.write("-" * 50 + "\n")
        f.write(f"   RÂ²å†³å®šç³»æ•°:     {metrics['r2_score']:.4f}\n")
        f.write(f"   RMSE(å‡æ–¹æ ¹è¯¯å·®): {metrics['rmse']:.4f} K\n")
        f.write(f"   MAE(å¹³å‡ç»å¯¹è¯¯å·®): {metrics['mae']:.4f} K\n")
        f.write(f"   MSE(å‡æ–¹è¯¯å·®):    {metrics['mse']:.4f}\n")
        f.write("-" * 50 + "\n\n")
        
        # æ€§èƒ½è§£è¯»æŒ‡å¯¼
        f.write(f"ğŸ“‹ æŒ‡æ ‡è§£è¯»è¯´æ˜\n")
        f.write(f"   â€¢ RÂ²åˆ†æ•°èŒƒå›´[0,1]ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºæ¨¡å‹è§£é‡ŠåŠ›è¶Šå¼º\n")
        f.write(f"   â€¢ RMSEå’ŒMAEå•ä½å‡ä¸ºå¼€å°”æ–‡(K)ï¼Œæ•°å€¼è¶Šå°é¢„æµ‹è¶Šç²¾å‡†\n")
        f.write(f"   â€¢ å»ºè®®å¯¹æ¯”ä¸åŒæ¨¡å‹æ¶æ„çš„æŒ‡æ ‡ä»¥é€‰æ‹©æœ€ä½³æ–¹æ¡ˆ\n")
    
    print(f"ğŸ“„ è¯¦ç»†è¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜è‡³: {filepath}")


def analyze_worst_predictions(model, processor, data_path, top_n=10):
    """
    é”™è¯¯æ ·æœ¬æ·±åº¦åˆ†æï¼šè¯†åˆ«é¢„æµ‹è¯¯å·®æœ€å¤§çš„æ ·æœ¬
    
    å‚æ•°:
        model (nn.Module): å·²è®­ç»ƒçš„é¢„æµ‹æ¨¡å‹
        processor (SuperconDataProcessor): æ•°æ®å¤„ç†å™¨å®ä¾‹
        data_path (str): åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„
        top_n (int): åˆ†æçš„æœ€å¤§è¯¯å·®æ ·æœ¬æ•°é‡ï¼Œé»˜è®¤10ä¸ª
    """
    print("\nğŸ” æ­£åœ¨æ‰§è¡Œé¢„æµ‹è¯¯å·®åˆ†æï¼ˆè¯†åˆ«æœ€å·®é¢„æµ‹æ ·æœ¬ï¼‰...")
    
    try:
        # å°è¯•CSVæ ¼å¼è¯»å–ï¼ˆé€—å·åˆ†éš”ï¼‰
        df = pd.read_csv(data_path, sep=',')
    except:
        # å›é€€åˆ°TSVæ ¼å¼è¯»å–ï¼ˆåˆ¶è¡¨ç¬¦åˆ†éš”ï¼‰
        df = pd.read_csv(data_path, sep='\t')
    
    # æ™ºèƒ½æ£€æµ‹Tcæ ‡ç­¾åˆ—åï¼ˆæ”¯æŒå¤šç§å‘½åçº¦å®šï¼‰
    tc_col = next(
        (c for c in df.columns if c.lower() in ['tc', 'critical_temp', 'temp', 'critical_temperature']), 
        None
    )
    
    if tc_col is None:
        print("âš ï¸ è­¦å‘Š: æœªæ£€æµ‹åˆ°Tcæ ‡ç­¾åˆ—ï¼Œé”™è¯¯åˆ†æç»ˆæ­¢")
        return
    
    # è·å–ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„æ•°æ®åˆ†å‰²ç´¢å¼•
    # ç¡®ä¿é”™è¯¯åˆ†æé’ˆå¯¹ç›¸åŒçš„æµ‹è¯•é›†æ ·æœ¬
    from sklearn.model_selection import train_test_split
    feature_df, valid_rows = processor.extract_features(df)
    df_clean = df.iloc[valid_rows].reset_index(drop=True)
    indices = np.arange(len(df_clean))
    _, test_indices = train_test_split(indices, test_size=0.2, random_state=42)
    
    # æå–æµ‹è¯•é›†æ•°æ®
    df_test = df_clean.iloc[test_indices].copy()
    X_test_np, _, _, _ = processor.load_and_process_data(data_path)
    # X_test_np å·²æŒ‰ç›¸åŒåˆ†å‰²æ¯”ä¾‹å¤„ç†ä¸ºæµ‹è¯•é›†
    
    # æ¨¡å‹æ¨ç†
    X_test_tensor = torch.FloatTensor(X_test_np).to(torch.device("cpu"))
    
    model.eval()
    with torch.no_grad():
        preds = model(X_test_tensor).numpy().flatten()
    
    # æ•°æ®é•¿åº¦å¯¹é½æ£€æŸ¥
    if len(preds) != len(df_test):
        min_len = min(len(preds), len(df_test))
        df_test = df_test.iloc[:min_len]
        preds = preds[:min_len]

    # è®¡ç®—ç»å¯¹è¯¯å·®å¹¶æ’åº
    df_test['Predicted_Tc'] = preds
    df_test['Abs_Error'] = np.abs(df_test[tc_col] - df_test['Predicted_Tc'])
    
    # è·å–è¯¯å·®æœ€å¤§çš„top_nä¸ªæ ·æœ¬
    worst_cases = df_test.sort_values(by='Abs_Error', ascending=False).head(top_n)
    
    # æ ¼å¼åŒ–è¾“å‡ºè¯¯å·®åˆ†æç»“æœ
    print(f"\nğŸ† é¢„æµ‹è¯¯å·®æœ€å¤§çš„{top_n}ä¸ªæ ·æœ¬:")
    print(f"{'åŒ–å­¦å¼':<20} | {'çœŸå®Tc':<10} | {'é¢„æµ‹Tc':<10} | {'ç»å¯¹è¯¯å·®':<10}")
    print("-" * 60)
    
    for _, row in worst_cases.iterrows():
        # æ™ºèƒ½æ£€æµ‹åŒ–å­¦å¼åˆ—å
        formula_col = next(
            (c for c in row.index if c.lower() in ['formula', 'name', 'material']), 
            'N/A'
        )
        formula = row[formula_col] if formula_col != 'N/A' else "N/A"
        
        # è¡Œæ ¼å¼è¾“å‡º
        print(f"{str(formula):<20} | {row[tc_col]:<10.2f} | {row['Predicted_Tc']:<10.2f} | {row['Abs_Error']:<10.2f}")
    
    # ä¿å­˜è¯¦ç»†é”™è¯¯åˆ†æç»“æœåˆ°CSVæ–‡ä»¶
    worst_cases.to_csv("error_analysis_worst_cases.csv", index=False, encoding='utf-8')
    print(f"\nâœ… è¯¯å·®æœ€å¤§æ ·æœ¬å·²ä¿å­˜è‡³ 'error_analysis_worst_cases.csv'")


# ==================== ç‹¬ç«‹è¿è¡Œæ¨¡å¼ ====================
if __name__ == "__main__":
    """
    è¯„ä¼°æ¨¡å—ç‹¬ç«‹è¿è¡Œæ¨¡å¼
    ç”¨äºåœ¨ä¸å¯åŠ¨å®Œæ•´è®­ç»ƒæµç¨‹çš„æƒ…å†µä¸‹æ‰§è¡Œæ¨¡å‹æ€§èƒ½è¯„ä¼°
    """
    print("--- æ¨¡å‹è¯„ä¼°æ¨¡å—ç‹¬ç«‹è¿è¡Œæ¨¡å¼ ---")
    
    # 1. è‡ªåŠ¨æ£€æµ‹æ•°æ®æ–‡ä»¶å’Œæ¨¡å‹æ–‡ä»¶è·¯å¾„
    train_path = "train.tsv" if os.path.exists("train.tsv") else "data/train.tsv"
    model_path = "best_model.pth"
    
    # æ–‡ä»¶å­˜åœ¨æ€§éªŒè¯
    if not os.path.exists(train_path):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶ train.tsv")
        sys.exit(1)
        
    if not os.path.exists(model_path):
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ°é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶ best_model.pth")
        print("ğŸ’¡ æç¤º: è¯·å…ˆè¿è¡Œ main.py è®­ç»ƒæ¨¡å‹")
        sys.exit(1)
    
    # 2. æ•°æ®é¢„å¤„ç†ï¼ˆä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„é«˜çº§ç‰¹å¾é…ç½®ï¼‰
    # ç¡®ä¿æ ‡å‡†åŒ–å™¨å‚æ•°ä¸è®­ç»ƒé˜¶æ®µå®Œå…¨ä¸€è‡´
    processor = SuperconDataProcessor(use_advanced_features=True)
    print("ğŸ“Š æ­£åœ¨å¤„ç†æ•°æ®ï¼ˆç¡®ä¿æ ‡å‡†åŒ–å™¨å‚æ•°ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰...")
    _, X_test, _, y_test = processor.load_and_process_data(train_path)
    
    # 3. æ¨¡å‹åŠ è½½
    input_dim = X_test.shape[1]  # ä»æ•°æ®è‡ªåŠ¨æ¨æ–­è¾“å…¥ç»´åº¦
    model = TcPredictorAdvanced(input_size=input_dim)
    
    try:
        # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆå¼ºåˆ¶CPUè®¾å¤‡ä»¥ç¡®ä¿å…¼å®¹æ€§ï¼‰
        model.load_state_dict(
            torch.load(model_path, map_location=torch.device("cpu"))
        )
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # 4. æ‰§è¡Œç»¼åˆè¯„ä¼°å¹¶ç”ŸæˆæŠ¥å‘Š
        metrics = evaluate_model(model, X_test, y_test)
        save_evaluation_report(metrics)  # ç”Ÿæˆevaluation_report.txt
        
        # 5. æ‰§è¡Œé”™è¯¯æ ·æœ¬åˆ†æ
        analyze_worst_predictions(model, processor, train_path)  # ç”Ÿæˆerror_analysis_worst_cases.csv
        
    except Exception as e:
        print(f"âŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ’¡ å¯èƒ½åŸå› : æ¨¡å‹æ¶æ„ä¸æƒé‡ä¸åŒ¹é…æˆ–æ•°æ®é¢„å¤„ç†ä¸ä¸€è‡´")